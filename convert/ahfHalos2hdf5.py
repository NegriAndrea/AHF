#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import numpy as np
import h5py
from pathlib import PurePath, Path
from astropy.table import Table, vstack
import astropy.units as u
# import astropy.cosmology.units as cu
# u.add_enabled_units(cu)

import argparse
import astropy.io.ascii

parser = argparse.ArgumentParser(description='Read all the halo tables,'
        ' concatenate them and write the result as hdf5 (optionally as an'
        ' astropy table)')

parser.add_argument('filename', type=str,
        help='Filename of the table to process, or ending part of the filename'
        ' is -n is active', nargs=1)

parser.add_argument('-n', type=int,
        help='Number of files to read for an table generated by AHF with MPI')

parser.add_argument('-o', action='store_true',
        help='overwrite output files')

parser.add_argument('-v', help='verbose output',
        action='store_true')

parser.add_argument('--astropy', action='store_true',
        help='Dump an astropy table in hdf5')

parser.add_argument('--ignore-missing', action='store_true',
        help='Do not check if all the files are there in case of multiple files')

args = parser.parse_args()

if args.n is None:
    filename = args.filename
    Nfiles = 1
else:
    # for parallel run, the format of the filename is different
    nameParts = PurePath(args.filename).name.split('.')
    filename = str(PurePath(args.filename).parent/(nameParts[0]+'.0000.'+'.'.join(nameParts[2:])))

    Nfiles = args.n
    n = len(list(Path(PurePath(args.filename).parent).glob(
        nameParts[0]+'.????.'+'.'.join(nameParts[2:]))))

    if not args.ignore_missing:
        if n != Nfiles:
            raise ValueError('Number of files does not match with -n')

try:
    t = Table.read(filename, format='ascii')
except IndexError as e:
    # if could be that we have 0 structures
    tmp = np.loadtxt(filename, comments='#')
    if len(tmp) == 0:
        print(f'No data in {filename}, skipping this file')
        exit()
    else:
        raise e

tables = [t]

for i in range(1,Nfiles):
    if args.v:
        print('reading ', i)
    nameParts = PurePath(args.filename).name.split('.')
    filename = str(PurePath(args.filename).parent/(
            nameParts[0]+'.'+str(i).zfill(4)+'.'+'.'.join(nameParts[2:])))
    tables.append(Table.read(filename,
            format='ascii.basic', guess=False, delimiter=r'\s',
            names=t.colnames))

bigT = vstack(tables)

names = bigT.colnames
for i, cname in enumerate(names):
    if i+1 <10:
        name = cname[:-3]
    elif i+1<100:
        name = cname[:-4]
    else:
        raise NotImplementedError
    bigT.rename_column(cname, name)


if args.n is None:
    # serial run of AHF
    outname = args.filename+'.h5'
else:
    outname = str(PurePath(args.filename).parent/(
                nameParts[0]+'.'+'.'.join(nameParts[2:])))+'.h5'

if args.v:
    print('writing ', outname)

if args.astropy:
    # dump the table in hdf5 as astropy table
    bigT.write(outname, format='hdf5', overwrite=args.o, compression=True)
else:
    # separate all the columns in an hdf5 file

    if args.o:
        writeMode = 'w'
    else:
        writeMode = 'w-'

    with h5py.File(outname, writeMode) as h5f:

        names = bigT.colnames
        for name in names:
            dset = h5f.create_dataset(name,
                    data = bigT[name],
                    compression="gzip", compression_opts=9)
